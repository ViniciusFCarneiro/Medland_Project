{
	"metadata": {
		"kernelspec": {
			"name": "glue_pyspark",
			"display_name": "Glue PySpark",
			"language": "python"
		},
		"language_info": {
			"name": "Python_Glue_Session",
			"mimetype": "text/x-python",
			"codemirror_mode": {
				"name": "python",
				"version": 3
			},
			"pygments_lexer": "python3",
			"file_extension": ".py"
		}
	},
	"nbformat_minor": 4,
	"nbformat": 4,
	"cells": [
		{
			"cell_type": "markdown",
			"source": "# AWS Glue Studio Notebook\n##### You are now running a AWS Glue Studio notebook; To start using your notebook you need to start an AWS Glue Interactive Session.\n",
			"metadata": {}
		},
		{
			"cell_type": "markdown",
			"source": "####  Run this cell to set up and start your interactive session.\n",
			"metadata": {}
		},
		{
			"cell_type": "code",
			"source": "\"\"\"\n# Timeout do job\n%idle_timeout 20\n\n# Versão do Glue\n%glue_version 3.0\n\n# Tipo de worker \"instância\"\n%worker_type G.1X\n\n# Quantidade de workers\n%number_of_workers 2\n\"\"\"\n\nimport sys\nfrom awsglue.transforms import *\nfrom awsglue.utils import getResolvedOptions\nfrom pyspark.context import SparkContext\nfrom awsglue.context import GlueContext\nfrom awsglue.job import Job\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql import functions as F\n  \nsc = SparkContext.getOrCreate()\nglueContext = GlueContext(sc)\nspark = glueContext.spark_session\njob = Job(glueContext)",
			"metadata": {
				"trusted": true,
				"scrolled": true,
				"tags": []
			},
			"execution_count": 1,
			"outputs": [
				{
					"name": "stdout",
					"text": "Welcome to the Glue Interactive Sessions Kernel\nFor more information on available magic commands, please type %help in any new cell.\n\nPlease view our Getting Started page to access the most up-to-date information on the Interactive Sessions kernel: https://docs.aws.amazon.com/glue/latest/dg/interactive-sessions.html\nInstalled kernel version: 0.38.1 \nAuthenticating with environment variables and user-defined glue_role_arn: arn:aws:iam::299399630206:role/acesso_total\nTrying to create a Glue session for the kernel.\nWorker Type: G.1X\nNumber of Workers: 5\nSession ID: 20702257-f224-4b12-80cf-38fe15a6eb83\nJob Type: glueetl\nApplying the following default arguments:\n--glue_kernel_version 0.38.1\n--enable-glue-datacatalog true\nWaiting for session 20702257-f224-4b12-80cf-38fe15a6eb83 to get into ready status...\nSession 20702257-f224-4b12-80cf-38fe15a6eb83 has been created.\n\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "markdown",
			"source": "### Tratando dados para a tabela PACIENTES\n\nOs dados estão separados em dois arquivos de acordo com sexo, serão carregados e unificado em um só",
			"metadata": {
				"tags": []
			}
		},
		{
			"cell_type": "code",
			"source": "# Criando dataframe do arquivo de pacientes sexo feminino\npacientes_f = spark.read.json(path = 's3://arquivos-medland/Raw data/pacientes_f.json', multiLine = True)\n\n# Criando dataframe do arquivo de pacientes sexo masculino\npacientes_m = spark.read.json(path = 's3://arquivos-medland/Raw data/pacientes_m.json', multiLine = True)",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 2,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "# União dos dois dataframes:\ndf = pacientes_f.union(pacientes_m).orderBy('nome')\nprint('O total de linhas do dataframe unificado é: {}'.format(df.count()))",
			"metadata": {
				"trusted": true
			},
			"execution_count": 3,
			"outputs": [
				{
					"name": "stdout",
					"text": "O total de linhas do dataframe unificado é: 1085\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "# Visualizando Schema:\ndf.printSchema()",
			"metadata": {
				"trusted": true
			},
			"execution_count": 4,
			"outputs": [
				{
					"name": "stdout",
					"text": "root\n |-- altura: string (nullable = true)\n |-- bairro: string (nullable = true)\n |-- celular: string (nullable = true)\n |-- cep: string (nullable = true)\n |-- cidade: string (nullable = true)\n |-- cor: string (nullable = true)\n |-- cpf: string (nullable = true)\n |-- data_nasc: string (nullable = true)\n |-- email: string (nullable = true)\n |-- endereco: string (nullable = true)\n |-- estado: string (nullable = true)\n |-- idade: long (nullable = true)\n |-- mae: string (nullable = true)\n |-- nome: string (nullable = true)\n |-- numero: long (nullable = true)\n |-- pai: string (nullable = true)\n |-- peso: long (nullable = true)\n |-- rg: string (nullable = true)\n |-- senha: string (nullable = true)\n |-- sexo: string (nullable = true)\n |-- signo: string (nullable = true)\n |-- telefone_fixo: string (nullable = true)\n |-- tipo_sanguineo: string (nullable = true)\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "markdown",
			"source": "#### Transformando os dados:",
			"metadata": {}
		},
		{
			"cell_type": "code",
			"source": "# Transformando a data de string para tipo date:\ndf = df.withColumn('data_nasc', F.to_date(F.col('data_nasc'), 'dd/MM/yyyy'))\n\n# Substituindo sexo:\ndf = df.replace(['Feminino', 'Masculino'], ['F', 'M'], 'sexo')\n\n# Removendo pontuação coluna CPF:\ndf = df.withColumn('cpf', F.regexp_replace('cpf', '[^\\w\\s]', ''))\n\n# Removendo pontuação coluna RG:\ndf = df.withColumn('rg', F.regexp_replace('rg', '[^\\w\\s]', ''))\n\n# Removendo espaços da coluna celular e telefone fixo:\ndf = df.withColumn('celular', F.regexp_replace(F.col('celular'),' ', '')).withColumn('telefone_fixo', F.regexp_replace(F.col('telefone_fixo'),' ', ''))\n\n# Coalesce para pegar o valor do telefone fixo se o celular estiver nulo + renomenado coluna:\ndf = df.withColumn('celular', \n                     F.coalesce(F.col('celular'), F.col('telefone_fixo')))\\\n                    .withColumnRenamed(\"celular\", \"telefone\")\n\n# Concatenando endereco com número para virar uma coluna só:\ndf = df.withColumn('endereco', F.concat_ws(' - ', F.col('endereco'), F.col('numero'), F.col('bairro')))",
			"metadata": {
				"trusted": true
			},
			"execution_count": 5,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "# Registrando o DataFrame como uma tabela temporária:\ndf.createOrReplaceTempView(\"temp_pacientes\")\n\n# Executando consulta SQL ordenando e renomeando colunas de acordo com o database para catalogar no GLUE\ndf_final = spark.sql(\"\"\"\n    SELECT\n        nome as NOME, \n        sexo as SEXO, \n        tipo_sanguineo as TP_SANGUE, \n        rg as RG, \n        cpf as CPF, \n        data_nasc as NASCIMENTO, \n        mae as NOME_MAE, \n        telefone as TELEFONE, \n        email as EMAIL, \n        endereco as ENDERECO, \n        cep as CEP, \n        cidade as CIDADE, \n        estado as ESTADO\n    FROM temp_pacientes\n\"\"\")\n\n# Exibindo o novo DataFrame\ndf_final.show(5, truncate = False)",
			"metadata": {
				"trusted": true
			},
			"execution_count": 6,
			"outputs": [
				{
					"name": "stdout",
					"text": "+--------------------------------+----+---------+---------+-----------+----------+---------------------+--------------+------------------------------------+------------------------------------------------+---------+--------------+------+\n|NOME                            |SEXO|TP_SANGUE|RG       |CPF        |NASCIMENTO|NOME_MAE             |TELEFONE      |EMAIL                               |ENDERECO                                        |CEP      |CIDADE        |ESTADO|\n+--------------------------------+----+---------+---------+-----------+----------+---------------------+--------------+------------------------------------+------------------------------------------------+---------+--------------+------+\n|Abel Renan Rodrigues            |M   |A-       |131145873|70264651634|1958-02-07|Liz Jaqueline Juliana|(31)3949-1110 |abel_rodrigues@ericsson.com         |Rua José Joaquim dos Santos - 211 - Copacabana  |31540-524|Belo Horizonte|MG    |\n|Adriana Bárbara Alice Cavalcanti|F   |A+       |346196814|51568798610|1990-07-09|Benedita Sophia      |(31)98898-7285|adriana.barbara.cavalcanti@modus.com|Rua Diabase - 462 - Prado                       |30411-060|Belo Horizonte|MG    |\n|Adriana Fernanda Rocha          |F   |O-       |235585622|12178421601|1947-04-03|Melissa Mariana Ayla |(31)3634-8472 |adrianafernandarocha@mfb.com.br     |Rua Turim - 931 - Santa Lúcia                   |30360-552|Belo Horizonte|MG    |\n|Adriana Jennifer Nina de Paula  |F   |A+       |237843092|29675190655|1979-01-01|Teresinha Débora     |(31)98149-0536|adriana-depaula84@yahooo.com.br     |Beco Rui Barbosa - 496 - Nossa Senhora de Fátima|30230-450|Belo Horizonte|MG    |\n|Adriana Manuela Novaes          |F   |A+       |197548970|02118616694|1985-01-24|Sophia Eloá          |(31)98727-7155|adrianamanuelanovaes@lta-am.com.br  |Rua Delta - 751 - Caiçaras                      |30775-400|Belo Horizonte|MG    |\n+--------------------------------+----+---------+---------+-----------+----------+---------------------+--------------+------------------------------------+------------------------------------------------+---------+--------------+------+\nonly showing top 5 rows\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "# Salvando o DF como parquet e definindo somente uma partição para gerar um arquivo único\ncaminho_pacientes = \"s3://arquivos-medland/ProcessedData/Pacientes\"\n\n#df_final.coalesce(1).write.parquet(caminho_pasta)\ndf_final.coalesce(1).write.mode(\"overwrite\").parquet(caminho_pacientes)",
			"metadata": {
				"trusted": true
			},
			"execution_count": 7,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "markdown",
			"source": "### Tratando dados para a tabela CONSULTAS",
			"metadata": {}
		},
		{
			"cell_type": "code",
			"source": "# Dataframe do arquivo de consultas\nconsultas = spark.read.csv(\"s3://arquivos-medland/Raw data/consultas.csv\", header = True, inferSchema = True, sep = \";\")",
			"metadata": {
				"trusted": true
			},
			"execution_count": 8,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "# Visualizando dataframe\nconsultas.show(10, truncate = False)",
			"metadata": {
				"trusted": true
			},
			"execution_count": 9,
			"outputs": [
				{
					"name": "stdout",
					"text": "+--------+------+--------+----------------+-------+--------------------------------------+---------+\n|Paciente|Medico|Hospital|Data            |Triagem|Diagnostico                           |Internado|\n+--------+------+--------+----------------+-------+--------------------------------------+---------+\n|1       |4     |1       |14/05/2022 09:13|2      |Sintomas médios de COVID SARS-CoV-2   |0        |\n|2       |5     |2       |09/03/2022 07:23|1      |Princípio  de infarto                 |0        |\n|3       |7     |1       |10/06/2022 05:47|4      |Febre/ Expectoração/mucosidade anormal|1        |\n|3       |5     |2       |16/09/2022 06:05|1      |Sintomas graves de COVID SARS-CoV-2   |0        |\n|4       |5     |2       |08/04/2022 09:29|4      |Infeccção intestinal                  |0        |\n|4       |6     |1       |23/06/2022 07:45|2      |Sintomas médios de COVID SARS-CoV-2   |0        |\n|5       |7     |2       |26/08/2022 06:49|4      |Perturbações visuais/ Dor no olho     |0        |\n|5       |1     |1       |21/12/2022 10:48|3      |Sinais/sintomas múltiplos das artic.  |1        |\n|6       |1     |1       |12/07/2022 10:31|3      |Sintomas médios de COVID SARS-CoV-2   |0        |\n|6       |4     |2       |17/11/2022 09:51|3      |Dores torácicas NE                    |1        |\n+--------+------+--------+----------------+-------+--------------------------------------+---------+\nonly showing top 10 rows\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "# Visualizando Schema\nconsultas.printSchema()",
			"metadata": {
				"trusted": true
			},
			"execution_count": 10,
			"outputs": [
				{
					"name": "stdout",
					"text": "root\n |-- Paciente: integer (nullable = true)\n |-- Medico: integer (nullable = true)\n |-- Hospital: integer (nullable = true)\n |-- Data: string (nullable = true)\n |-- Triagem: integer (nullable = true)\n |-- Diagnostico: string (nullable = true)\n |-- Internado: integer (nullable = true)\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "# Transformando a data de string para tipo date\nconsultas = consultas.withColumn(\"Data\", F.to_timestamp(\"Data\", \"dd/MM/yyyy HH:mm\"))\n\n# Ordenando dataframe pela colun data\nconsultas = consultas.orderBy(\"Data\")",
			"metadata": {
				"trusted": true
			},
			"execution_count": 11,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "# Visualizando Schema\nconsultas.printSchema()",
			"metadata": {
				"trusted": true
			},
			"execution_count": 12,
			"outputs": [
				{
					"name": "stdout",
					"text": "root\n |-- Paciente: integer (nullable = true)\n |-- Medico: integer (nullable = true)\n |-- Hospital: integer (nullable = true)\n |-- Data: timestamp (nullable = true)\n |-- Triagem: integer (nullable = true)\n |-- Diagnostico: string (nullable = true)\n |-- Internado: integer (nullable = true)\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "from pyspark.sql.window import Window\n\n# Criando uma janela com base na coluna 'DATA' para criar uma ordenação que será o ID_CONSULTA (Chave primária)\n# A função window é usada para fornecer o número sequencial da linha começando de 1 ao resultado de cada partição da janela\nwindow = Window.orderBy(F.col('DATA'))\n\n# A função row_number atribui um número sequencial para cada linha do dataframe com base na ordem de classificação especificada pela window criada\nconsultas = consultas.withColumn(\"ID_CONSULTA\", F.row_number().over(window))",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 13,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "# Registrando o DataFrame como uma tabela temporária:\nconsultas.createOrReplaceTempView(\"temp_consultas\")\n\n# Executando consulta SQL ordenando e renomeando colunas de acordo com o database para catalogar no GLUE\nconsultas = spark.sql(\"\"\"\n    SELECT\n        ID_CONSULTA,\n        Paciente as ID_PACIENTE,\n        Medico as ID_MEDICO,\n        Hospital as ID_HOSPITAL,\n        Data as DATA,\n        Triagem as GRAU_RISCO,\n        Diagnostico as DIAGNOSTICO,\n        Internado as INTERNACAO \n    FROM temp_consultas\n\"\"\")\n\n# Exibindo o novo DataFrame\nconsultas.show(5, truncate = False)",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 14,
			"outputs": [
				{
					"name": "stdout",
					"text": "+-----------+-----------+---------+-----------+-------------------+----------+------------------------------------+----------+\n|ID_CONSULTA|ID_PACIENTE|ID_MEDICO|ID_HOSPITAL|DATA               |GRAU_RISCO|DIAGNOSTICO                         |INTERNACAO|\n+-----------+-----------+---------+-----------+-------------------+----------+------------------------------------+----------+\n|1          |117        |2        |1          |2022-01-01 10:27:00|2         |Sintomas graves de COVID SARS-CoV-2 |0         |\n|2          |131        |1        |2          |2022-01-03 07:49:00|4         |Hipertensão sem complicações        |0         |\n|3          |130        |9        |1          |2022-01-05 08:18:00|4         |Cefaleia/ Febre/ Tosse              |0         |\n|4          |7          |7        |1          |2022-01-10 00:50:00|4         |Sintomas médios de COVID SARS-CoV-2 |0         |\n|5          |26         |1        |1          |2022-01-10 08:58:00|4         |Sinais/sintomas múltiplos das artic.|1         |\n+-----------+-----------+---------+-----------+-------------------+----------+------------------------------------+----------+\nonly showing top 5 rows\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "# Salvando o DF como parquet e definindo somente uma partição para gerar um arquivo único\ncaminho_consultas = \"s3://arquivos-medland/ProcessedData/Consultas\"\n\nconsultas.coalesce(1).write.mode(\"overwrite\").parquet(caminho_consultas)",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 15,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		}
	]
}